{"ast":null,"code":"/*!\r\n * dataFile.js\r\n *\r\n * Copyright (c) 2012-2018 mooster@42at.com\r\n * https://github.com/moos/wordpos\r\n *\r\n * Portions: Copyright (c) 2011, Chris Umbel\r\n *\r\n * Released under MIT license\r\n */\nvar fs = require('fs'),\n    path = require('path'),\n    _ = require('underscore');\n/**\r\n * sanity check read data - line must start with zero-padded location\r\n *\r\n * @param line {string} - line data read\r\n * @return {boolean} true if line data is good\r\n */\n\n\nfunction dataCheck(line, location) {\n  var pad = '00000000',\n      // 8 zeros\n  padded = String(pad + location).slice(-pad.length);\n  return line.indexOf(padded) === 0;\n}\n/**\r\n * parse a single data file line, returning data object\r\n *\r\n * @param line {string} - a single line from WordNet data file\r\n * @returns {object}\r\n *\r\n * Credit for this routine to https://github.com/NaturalNode/natural\r\n */\n\n\nfunction lineDataToJSON(line, location) {\n  if (!dataCheck(line, location)) return new Error('Bad data at location ' + location);\n  var data = line.split('| '),\n      tokens = data[0].split(/\\s+/),\n      ptrs = [],\n      wCnt = parseInt(tokens[3], 16),\n      synonyms = [],\n      i;\n\n  for (i = 0; i < wCnt; i++) {\n    synonyms.push(tokens[4 + i * 2]);\n  }\n\n  var ptrOffset = (wCnt - 1) * 2 + 6;\n\n  for (i = 0; i < parseInt(tokens[ptrOffset], 10); i++) {\n    ptrs.push({\n      pointerSymbol: tokens[ptrOffset + 1 + i * 4],\n      synsetOffset: parseInt(tokens[ptrOffset + 2 + i * 4], 10),\n      pos: tokens[ptrOffset + 3 + i * 4],\n      sourceTarget: tokens[ptrOffset + 4 + i * 4]\n    });\n  } // break \"gloss\" into definition vs. examples\n\n\n  var glossArray = data[1].split(\"; \");\n  var definition = glossArray[0];\n  var examples = glossArray.slice(1);\n  var lexFilenum = parseInt(tokens[1], 10);\n\n  for (var k = 0; k < examples.length; k++) {\n    examples[k] = examples[k].replace(/\\\"/g, '').replace(/\\s\\s+/g, '');\n  }\n\n  return {\n    synsetOffset: parseInt(tokens[0], 10),\n    lexFilenum: lexFilenum,\n    lexName: DataFile.LEX_NAMES[lexFilenum],\n    pos: tokens[2],\n    wCnt: wCnt,\n    lemma: tokens[4],\n    synonyms: synonyms,\n    lexId: tokens[5],\n    ptrs: ptrs,\n    gloss: data[1],\n    def: definition,\n    exp: examples\n  };\n}\n/**\r\n * read data file at location (bound to a data file).\r\n * Reads nominal length and checks for EOL.  Continue reading until EOL.\r\n *\r\n * @param location {Number} - seek location\r\n * @param callback {function} - callback function\r\n */\n\n\nfunction readLocation(location, callback) {\n  //console.log('## read location ', this.fileName, location);\n  var file = this,\n      str = '',\n      len = file.nominalLineLength,\n      buffer = new Buffer.alloc(len);\n  readChunk(location, function (err, count) {\n    if (err) {\n      //console.log(err);\n      callback(err);\n      return;\n    } //console.log('  read %d bytes at <%d>', count, location);\n\n\n    callback(null, lineDataToJSON(str, location));\n  });\n\n  function readChunk(pos, cb) {\n    var nonDataErr = new Error('no data at offset ' + pos);\n    fs.read(file.fd, buffer, 0, len, pos, function (err, count) {\n      if (!count) return cb(nonDataErr, count);\n      str += buffer.toString('ascii');\n      var eol = str.indexOf('\\n'); //console.log('  -- read %d bytes at <%d>', count, pos, eol);\n\n      if (count && eol === -1 && len < file.maxLineLength) {\n        // continue reading\n        return readChunk(pos + count, cb);\n      }\n\n      str = str.substr(0, eol);\n      if (str === '' && !err) err = nonDataErr;\n      cb(err, count);\n    });\n  }\n}\n/**\r\n * main lookup function\r\n *\r\n * @param offsets {array} - array of offsets to lookup (obtained from index.find())\r\n * @param callback{function} (optional) - callback function\r\n * @returns {Promise}\r\n */\n\n\nfunction lookup(offsets, callback) {\n  var results = [],\n      self = this,\n      single = !_.isArray(offsets);\n  if (single) offsets = [offsets];\n  return new Promise(function (resolve, reject) {\n    offsets.map(function (offset) {\n      return _.partial(readLocation.bind(self), offset);\n    }).map(promisifyInto(results)).reduce(serialize, openFile()).then(done).catch(done);\n\n    function done(lastResult) {\n      closeFile();\n\n      if (lastResult instanceof Error) {\n        callback && callback(lastResult, single ? {} : []);\n        reject(lastResult);\n      } else {\n        if (single) results = results[0];\n        callback && callback(null, results);\n        resolve(results);\n      }\n    }\n  });\n\n  function serialize(prev, next) {\n    return prev.then(next);\n  }\n\n  function openFile() {\n    if (!self.fd) {\n      // console.log(' ... opening', self.filePath);\n      self.fd = fs.openSync(self.filePath, 'r');\n    } // ref count so we know when to close the main index file\n\n\n    ++self.refcount;\n    return Promise.resolve();\n  }\n\n  function closeFile() {\n    if (--self.refcount === 0) {\n      // console.log(' ... closing', self.filePath);\n      fs.closeSync(self.fd);\n      self.fd = null;\n    }\n\n    return Promise.resolve();\n  }\n}\n/**\r\n * turn ordinary function into a promising one!\r\n *\r\n * @param collect {Array} - used to collect results\r\n * @returns {Function}\r\n */\n\n\nfunction promisifyInto(collect) {\n  return function (fn) {\n    return function () {\n      return new Promise(function (resolve, reject) {\n        fn(function (error, result) {\n          // Note: callback signature!\n          if (error) {\n            reject(error);\n          } else {\n            collect && collect.push(result);\n            resolve(result);\n          }\n        });\n      });\n    };\n  };\n}\n/**\r\n * DataFile class\r\n *\r\n * @param dictPath {string} - path to dict folder\r\n * @param name {string} - POS name\r\n * @constructor\r\n */\n\n\nvar DataFile = function (dictPath, name) {\n  this.dictPath = dictPath;\n  this.fileName = 'data.' + name;\n  this.filePath = path.join(this.dictPath, this.fileName);\n  this.maxLineLength = DataFile.MAX_LINE_LENGTH[name];\n  this.nominalLineLength = MAX_SINGLE_READ_LENGTH;\n  this.refcount = 0;\n};\n/**\r\n * maximum read length at a time\r\n * @type {Number}\r\n */\n\n\nvar MAX_SINGLE_READ_LENGTH = 512;\n/**\r\n * lookup\r\n */\n\nDataFile.prototype.lookup = lookup;\n/**\r\n * maximum line length in each data file - used to optimize reads\r\n *\r\n * wc -L data.adv as of v3.1\r\n */\n\nDataFile.MAX_LINE_LENGTH = {\n  noun: 12972,\n  verb: 7713,\n  adj: 2794,\n  adv: 638\n};\n/**\r\n * map of lexFilenum to lex names\r\n *\r\n * @see https://wordnet.princeton.edu/wordnet/man/lexnames.5WN.html\r\n * @type {string[]}\r\n */\n\nDataFile.LEX_NAMES = ['adj.all', 'adj.pert', 'adv.all', 'noun.Tops', 'noun.act', 'noun.animal', 'noun.artifact', 'noun.attribute', 'noun.body', 'noun.cognition', 'noun.communication', 'noun.event', 'noun.feeling', 'noun.food', 'noun.group', 'noun.location', 'noun.motive', 'noun.object', 'noun.person', 'noun.phenomenon', 'noun.plant', 'noun.possession', 'noun.process', 'noun.quantity', 'noun.relation', 'noun.shape', 'noun.state', 'noun.substance', 'noun.time', 'verb.body', 'verb.change', 'verb.cognition', 'verb.communication', 'verb.competition', 'verb.consumption', 'verb.contact', 'verb.creation', 'verb.emotion', 'verb.motion', 'verb.perception', 'verb.possession', 'verb.social', 'verb.stative', 'verb.weather', 'adj.ppl'];\nmodule.exports = DataFile;","map":{"version":3,"sources":["/Users/tenzy/Documents/work/vata-hackathon-fe/atva/node_modules/wordpos/src/dataFile.js"],"names":["fs","require","path","_","dataCheck","line","location","pad","padded","String","slice","length","indexOf","lineDataToJSON","Error","data","split","tokens","ptrs","wCnt","parseInt","synonyms","i","push","ptrOffset","pointerSymbol","synsetOffset","pos","sourceTarget","glossArray","definition","examples","lexFilenum","k","replace","lexName","DataFile","LEX_NAMES","lemma","lexId","gloss","def","exp","readLocation","callback","file","str","len","nominalLineLength","buffer","Buffer","alloc","readChunk","err","count","cb","nonDataErr","read","fd","toString","eol","maxLineLength","substr","lookup","offsets","results","self","single","isArray","Promise","resolve","reject","map","offset","partial","bind","promisifyInto","reduce","serialize","openFile","then","done","catch","lastResult","closeFile","prev","next","openSync","filePath","refcount","closeSync","collect","fn","error","result","dictPath","name","fileName","join","MAX_LINE_LENGTH","MAX_SINGLE_READ_LENGTH","prototype","noun","verb","adj","adv","module","exports"],"mappings":"AAAA;;;;;;;;;;AAWA,IAAIA,EAAE,GAAGC,OAAO,CAAC,IAAD,CAAhB;AAAA,IACEC,IAAI,GAAGD,OAAO,CAAC,MAAD,CADhB;AAAA,IAEEE,CAAC,GAAGF,OAAO,CAAC,YAAD,CAFb;AAIA;;;;;;;;AAMA,SAASG,SAAT,CAAmBC,IAAnB,EAAyBC,QAAzB,EAAmC;AACjC,MAAIC,GAAG,GAAG,UAAV;AAAA,MAAsB;AACpBC,EAAAA,MAAM,GAAGC,MAAM,CAACF,GAAG,GAAGD,QAAP,CAAN,CAAuBI,KAAvB,CAA8B,CAAEH,GAAG,CAACI,MAApC,CADX;AAEA,SAAON,IAAI,CAACO,OAAL,CAAaJ,MAAb,MAAyB,CAAhC;AACD;AAED;;;;;;;;;;AAQA,SAASK,cAAT,CAAwBR,IAAxB,EAA8BC,QAA9B,EAAwC;AACtC,MAAI,CAACF,SAAS,CAACC,IAAD,EAAOC,QAAP,CAAd,EAAgC,OAAO,IAAIQ,KAAJ,CAAU,0BAA0BR,QAApC,CAAP;AAEhC,MAAIS,IAAI,GAAGV,IAAI,CAACW,KAAL,CAAW,IAAX,CAAX;AAAA,MACEC,MAAM,GAAGF,IAAI,CAAC,CAAD,CAAJ,CAAQC,KAAR,CAAc,KAAd,CADX;AAAA,MAEEE,IAAI,GAAG,EAFT;AAAA,MAGEC,IAAI,GAAGC,QAAQ,CAACH,MAAM,CAAC,CAAD,CAAP,EAAY,EAAZ,CAHjB;AAAA,MAIEI,QAAQ,GAAG,EAJb;AAAA,MAKEC,CALF;;AAOA,OAAIA,CAAC,GAAG,CAAR,EAAWA,CAAC,GAAGH,IAAf,EAAqBG,CAAC,EAAtB,EAA0B;AACxBD,IAAAA,QAAQ,CAACE,IAAT,CAAcN,MAAM,CAAC,IAAIK,CAAC,GAAG,CAAT,CAApB;AACD;;AAED,MAAIE,SAAS,GAAG,CAACL,IAAI,GAAG,CAAR,IAAa,CAAb,GAAiB,CAAjC;;AACA,OAAIG,CAAC,GAAG,CAAR,EAAWA,CAAC,GAAGF,QAAQ,CAACH,MAAM,CAACO,SAAD,CAAP,EAAoB,EAApB,CAAvB,EAAgDF,CAAC,EAAjD,EAAqD;AACnDJ,IAAAA,IAAI,CAACK,IAAL,CAAU;AACRE,MAAAA,aAAa,EAAER,MAAM,CAACO,SAAS,GAAG,CAAZ,GAAgBF,CAAC,GAAG,CAArB,CADb;AAERI,MAAAA,YAAY,EAAEN,QAAQ,CAACH,MAAM,CAACO,SAAS,GAAG,CAAZ,GAAgBF,CAAC,GAAG,CAArB,CAAP,EAAgC,EAAhC,CAFd;AAGRK,MAAAA,GAAG,EAAEV,MAAM,CAACO,SAAS,GAAG,CAAZ,GAAgBF,CAAC,GAAG,CAArB,CAHH;AAIRM,MAAAA,YAAY,EAAEX,MAAM,CAACO,SAAS,GAAG,CAAZ,GAAgBF,CAAC,GAAG,CAArB;AAJZ,KAAV;AAMD,GAtBqC,CAwBtC;;;AACA,MAAIO,UAAU,GAAGd,IAAI,CAAC,CAAD,CAAJ,CAAQC,KAAR,CAAc,IAAd,CAAjB;AACA,MAAIc,UAAU,GAAGD,UAAU,CAAC,CAAD,CAA3B;AACA,MAAIE,QAAQ,GAAGF,UAAU,CAACnB,KAAX,CAAiB,CAAjB,CAAf;AACA,MAAIsB,UAAU,GAAGZ,QAAQ,CAACH,MAAM,CAAC,CAAD,CAAP,EAAY,EAAZ,CAAzB;;AAEA,OAAK,IAAIgB,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGF,QAAQ,CAACpB,MAA7B,EAAqCsB,CAAC,EAAtC,EAA0C;AACxCF,IAAAA,QAAQ,CAACE,CAAD,CAAR,GAAcF,QAAQ,CAACE,CAAD,CAAR,CAAYC,OAAZ,CAAoB,KAApB,EAA0B,EAA1B,EAA8BA,OAA9B,CAAsC,QAAtC,EAA+C,EAA/C,CAAd;AACD;;AAED,SAAO;AACLR,IAAAA,YAAY,EAAEN,QAAQ,CAACH,MAAM,CAAC,CAAD,CAAP,EAAY,EAAZ,CADjB;AAELe,IAAAA,UAAU,EAAEA,UAFP;AAGLG,IAAAA,OAAO,EAAEC,QAAQ,CAACC,SAAT,CAAoBL,UAApB,CAHJ;AAILL,IAAAA,GAAG,EAAEV,MAAM,CAAC,CAAD,CAJN;AAKLE,IAAAA,IAAI,EAAEA,IALD;AAMLmB,IAAAA,KAAK,EAAErB,MAAM,CAAC,CAAD,CANR;AAOLI,IAAAA,QAAQ,EAAEA,QAPL;AAQLkB,IAAAA,KAAK,EAAEtB,MAAM,CAAC,CAAD,CARR;AASLC,IAAAA,IAAI,EAAEA,IATD;AAULsB,IAAAA,KAAK,EAAEzB,IAAI,CAAC,CAAD,CAVN;AAWL0B,IAAAA,GAAG,EAAEX,UAXA;AAYLY,IAAAA,GAAG,EAAEX;AAZA,GAAP;AAcD;AAED;;;;;;;;;AAOA,SAASY,YAAT,CAAsBrC,QAAtB,EAAgCsC,QAAhC,EAA0C;AACxC;AACA,MACEC,IAAI,GAAG,IADT;AAAA,MAEEC,GAAG,GAAG,EAFR;AAAA,MAGEC,GAAG,GAAGF,IAAI,CAACG,iBAHb;AAAA,MAIEC,MAAM,GAAG,IAAIC,MAAM,CAACC,KAAX,CAAiBJ,GAAjB,CAJX;AAMAK,EAAAA,SAAS,CAAC9C,QAAD,EAAW,UAAS+C,GAAT,EAAcC,KAAd,EAAqB;AACvC,QAAID,GAAJ,EAAS;AACP;AACAT,MAAAA,QAAQ,CAACS,GAAD,CAAR;AACA;AACD,KALsC,CAMvC;;;AACAT,IAAAA,QAAQ,CAAC,IAAD,EAAO/B,cAAc,CAACiC,GAAD,EAAMxC,QAAN,CAArB,CAAR;AACD,GARQ,CAAT;;AAUA,WAAS8C,SAAT,CAAmBzB,GAAnB,EAAwB4B,EAAxB,EAA4B;AAC1B,QAAIC,UAAU,GAAG,IAAI1C,KAAJ,CAAU,uBAAuBa,GAAjC,CAAjB;AAEA3B,IAAAA,EAAE,CAACyD,IAAH,CAAQZ,IAAI,CAACa,EAAb,EAAiBT,MAAjB,EAAyB,CAAzB,EAA4BF,GAA5B,EAAiCpB,GAAjC,EAAsC,UAAU0B,GAAV,EAAeC,KAAf,EAAsB;AAC1D,UAAI,CAACA,KAAL,EAAY,OAAOC,EAAE,CAACC,UAAD,EAAaF,KAAb,CAAT;AAEZR,MAAAA,GAAG,IAAIG,MAAM,CAACU,QAAP,CAAgB,OAAhB,CAAP;AACA,UAAIC,GAAG,GAAGd,GAAG,CAAClC,OAAJ,CAAY,IAAZ,CAAV,CAJ0D,CAK1D;;AACA,UAAI0C,KAAK,IAAIM,GAAG,KAAK,CAAC,CAAlB,IAAuBb,GAAG,GAAGF,IAAI,CAACgB,aAAtC,EAAqD;AACnD;AACA,eAAOT,SAAS,CAACzB,GAAG,GAAG2B,KAAP,EAAcC,EAAd,CAAhB;AACD;;AAEDT,MAAAA,GAAG,GAAGA,GAAG,CAACgB,MAAJ,CAAW,CAAX,EAAcF,GAAd,CAAN;AACA,UAAId,GAAG,KAAK,EAAR,IAAc,CAACO,GAAnB,EAAwBA,GAAG,GAAGG,UAAN;AACxBD,MAAAA,EAAE,CAACF,GAAD,EAAMC,KAAN,CAAF;AACD,KAdD;AAeD;AACF;AAED;;;;;;;;;AAOA,SAASS,MAAT,CAAgBC,OAAhB,EAAyBpB,QAAzB,EAAmC;AACjC,MAAIqB,OAAO,GAAG,EAAd;AAAA,MACEC,IAAI,GAAG,IADT;AAAA,MAEEC,MAAM,GAAG,CAAChE,CAAC,CAACiE,OAAF,CAAUJ,OAAV,CAFZ;AAIA,MAAIG,MAAJ,EAAYH,OAAO,GAAG,CAACA,OAAD,CAAV;AACZ,SAAO,IAAIK,OAAJ,CAAY,UAASC,OAAT,EAAkBC,MAAlB,EAA0B;AAC3CP,IAAAA,OAAO,CACJQ,GADH,CACO,UAAUC,MAAV,EAAkB;AACrB,aAAOtE,CAAC,CAACuE,OAAF,CAAU/B,YAAY,CAACgC,IAAb,CAAkBT,IAAlB,CAAV,EAAmCO,MAAnC,CAAP;AACD,KAHH,EAIGD,GAJH,CAIOI,aAAa,CAACX,OAAD,CAJpB,EAKGY,MALH,CAKUC,SALV,EAKqBC,QAAQ,EAL7B,EAMGC,IANH,CAMQC,IANR,EAOGC,KAPH,CAOSD,IAPT;;AASA,aAASA,IAAT,CAAcE,UAAd,EAA0B;AACxBC,MAAAA,SAAS;;AACT,UAAID,UAAU,YAAYrE,KAA1B,EAAiC;AAC/B8B,QAAAA,QAAQ,IAAIA,QAAQ,CAACuC,UAAD,EAAahB,MAAM,GAAG,EAAH,GAAO,EAA1B,CAApB;AACAI,QAAAA,MAAM,CAACY,UAAD,CAAN;AACD,OAHD,MAGO;AACL,YAAIhB,MAAJ,EAAYF,OAAO,GAAGA,OAAO,CAAC,CAAD,CAAjB;AACZrB,QAAAA,QAAQ,IAAIA,QAAQ,CAAC,IAAD,EAAOqB,OAAP,CAApB;AACAK,QAAAA,OAAO,CAACL,OAAD,CAAP;AACD;AACF;AACF,GArBM,CAAP;;AAuBA,WAASa,SAAT,CAAmBO,IAAnB,EAAyBC,IAAzB,EAA+B;AAC7B,WAAOD,IAAI,CAACL,IAAL,CAAUM,IAAV,CAAP;AACD;;AAED,WAASP,QAAT,GAAoB;AAClB,QAAI,CAACb,IAAI,CAACR,EAAV,EAAc;AACZ;AACAQ,MAAAA,IAAI,CAACR,EAAL,GAAU1D,EAAE,CAACuF,QAAH,CAAYrB,IAAI,CAACsB,QAAjB,EAA2B,GAA3B,CAAV;AACD,KAJiB,CAKlB;;;AACA,MAAEtB,IAAI,CAACuB,QAAP;AACA,WAAOpB,OAAO,CAACC,OAAR,EAAP;AACD;;AAED,WAASc,SAAT,GAAqB;AACnB,QAAI,EAAElB,IAAI,CAACuB,QAAP,KAAoB,CAAxB,EAA2B;AACzB;AACAzF,MAAAA,EAAE,CAAC0F,SAAH,CAAaxB,IAAI,CAACR,EAAlB;AACAQ,MAAAA,IAAI,CAACR,EAAL,GAAU,IAAV;AACD;;AACD,WAAOW,OAAO,CAACC,OAAR,EAAP;AACD;AACF;AAED;;;;;;;;AAMA,SAASM,aAAT,CAAuBe,OAAvB,EAAgC;AAC9B,SAAO,UAASC,EAAT,EAAa;AAClB,WAAO,YAAW;AAChB,aAAO,IAAIvB,OAAJ,CAAY,UAAUC,OAAV,EAAmBC,MAAnB,EAA2B;AAC5CqB,QAAAA,EAAE,CAAC,UAAUC,KAAV,EAAiBC,MAAjB,EAAyB;AAAI;AAC9B,cAAID,KAAJ,EAAW;AACTtB,YAAAA,MAAM,CAACsB,KAAD,CAAN;AACD,WAFD,MAGK;AACHF,YAAAA,OAAO,IAAIA,OAAO,CAACpE,IAAR,CAAauE,MAAb,CAAX;AACAxB,YAAAA,OAAO,CAACwB,MAAD,CAAP;AACD;AACF,SARC,CAAF;AASD,OAVM,CAAP;AAWD,KAZD;AAaD,GAdD;AAeD;AAGD;;;;;;;;;AAOA,IAAI1D,QAAQ,GAAG,UAAS2D,QAAT,EAAmBC,IAAnB,EAAyB;AACtC,OAAKD,QAAL,GAAgBA,QAAhB;AACA,OAAKE,QAAL,GAAgB,UAAUD,IAA1B;AACA,OAAKR,QAAL,GAAgBtF,IAAI,CAACgG,IAAL,CAAU,KAAKH,QAAf,EAAyB,KAAKE,QAA9B,CAAhB;AAEA,OAAKpC,aAAL,GAAqBzB,QAAQ,CAAC+D,eAAT,CAA0BH,IAA1B,CAArB;AACA,OAAKhD,iBAAL,GAAyBoD,sBAAzB;AACA,OAAKX,QAAL,GAAgB,CAAhB;AACD,CARD;AAUA;;;;;;AAIA,IAAIW,sBAAsB,GAAG,GAA7B;AAEA;;;;AAGAhE,QAAQ,CAACiE,SAAT,CAAmBtC,MAAnB,GAA4BA,MAA5B;AAGA;;;;;;AAKA3B,QAAQ,CAAC+D,eAAT,GAA2B;AACzBG,EAAAA,IAAI,EAAE,KADmB;AAEzBC,EAAAA,IAAI,EAAE,IAFmB;AAGzBC,EAAAA,GAAG,EAAE,IAHoB;AAIzBC,EAAAA,GAAG,EAAE;AAJoB,CAA3B;AAOA;;;;;;;AAMArE,QAAQ,CAACC,SAAT,GAAqB,CACnB,SADmB,EAEnB,UAFmB,EAGnB,SAHmB,EAInB,WAJmB,EAKnB,UALmB,EAMnB,aANmB,EAOnB,eAPmB,EAQnB,gBARmB,EASnB,WATmB,EAUnB,gBAVmB,EAWnB,oBAXmB,EAYnB,YAZmB,EAanB,cAbmB,EAcnB,WAdmB,EAenB,YAfmB,EAgBnB,eAhBmB,EAiBnB,aAjBmB,EAkBnB,aAlBmB,EAmBnB,aAnBmB,EAoBnB,iBApBmB,EAqBnB,YArBmB,EAsBnB,iBAtBmB,EAuBnB,cAvBmB,EAwBnB,eAxBmB,EAyBnB,eAzBmB,EA0BnB,YA1BmB,EA2BnB,YA3BmB,EA4BnB,gBA5BmB,EA6BnB,WA7BmB,EA8BnB,WA9BmB,EA+BnB,aA/BmB,EAgCnB,gBAhCmB,EAiCnB,oBAjCmB,EAkCnB,kBAlCmB,EAmCnB,kBAnCmB,EAoCnB,cApCmB,EAqCnB,eArCmB,EAsCnB,cAtCmB,EAuCnB,aAvCmB,EAwCnB,iBAxCmB,EAyCnB,iBAzCmB,EA0CnB,aA1CmB,EA2CnB,cA3CmB,EA4CnB,cA5CmB,EA6CnB,SA7CmB,CAArB;AAgDAqE,MAAM,CAACC,OAAP,GAAiBvE,QAAjB","sourcesContent":["/*!\r\n * dataFile.js\r\n *\r\n * Copyright (c) 2012-2018 mooster@42at.com\r\n * https://github.com/moos/wordpos\r\n *\r\n * Portions: Copyright (c) 2011, Chris Umbel\r\n *\r\n * Released under MIT license\r\n */\r\n\r\nvar fs = require('fs'),\r\n  path = require('path'),\r\n  _ = require('underscore');\r\n\r\n/**\r\n * sanity check read data - line must start with zero-padded location\r\n *\r\n * @param line {string} - line data read\r\n * @return {boolean} true if line data is good\r\n */\r\nfunction dataCheck(line, location) {\r\n  var pad = '00000000', // 8 zeros\r\n    padded = String(pad + location).slice( - pad.length);\r\n  return line.indexOf(padded) === 0;\r\n}\r\n\r\n/**\r\n * parse a single data file line, returning data object\r\n *\r\n * @param line {string} - a single line from WordNet data file\r\n * @returns {object}\r\n *\r\n * Credit for this routine to https://github.com/NaturalNode/natural\r\n */\r\nfunction lineDataToJSON(line, location) {\r\n  if (!dataCheck(line, location)) return new Error('Bad data at location ' + location);\r\n\r\n  var data = line.split('| '),\r\n    tokens = data[0].split(/\\s+/),\r\n    ptrs = [],\r\n    wCnt = parseInt(tokens[3], 16),\r\n    synonyms = [],\r\n    i;\r\n\r\n  for(i = 0; i < wCnt; i++) {\r\n    synonyms.push(tokens[4 + i * 2]);\r\n  }\r\n\r\n  var ptrOffset = (wCnt - 1) * 2 + 6;\r\n  for(i = 0; i < parseInt(tokens[ptrOffset], 10); i++) {\r\n    ptrs.push({\r\n      pointerSymbol: tokens[ptrOffset + 1 + i * 4],\r\n      synsetOffset: parseInt(tokens[ptrOffset + 2 + i * 4], 10),\r\n      pos: tokens[ptrOffset + 3 + i * 4],\r\n      sourceTarget: tokens[ptrOffset + 4 + i * 4]\r\n    });\r\n  }\r\n\r\n  // break \"gloss\" into definition vs. examples\r\n  var glossArray = data[1].split(\"; \");\r\n  var definition = glossArray[0];\r\n  var examples = glossArray.slice(1);\r\n  var lexFilenum = parseInt(tokens[1], 10);\r\n\r\n  for (var k = 0; k < examples.length; k++) {\r\n    examples[k] = examples[k].replace(/\\\"/g,'').replace(/\\s\\s+/g,'');\r\n  }\r\n\r\n  return {\r\n    synsetOffset: parseInt(tokens[0], 10),\r\n    lexFilenum: lexFilenum,\r\n    lexName: DataFile.LEX_NAMES[ lexFilenum ],\r\n    pos: tokens[2],\r\n    wCnt: wCnt,\r\n    lemma: tokens[4],\r\n    synonyms: synonyms,\r\n    lexId: tokens[5],\r\n    ptrs: ptrs,\r\n    gloss: data[1],\r\n    def: definition,\r\n    exp: examples\r\n  };\r\n}\r\n\r\n/**\r\n * read data file at location (bound to a data file).\r\n * Reads nominal length and checks for EOL.  Continue reading until EOL.\r\n *\r\n * @param location {Number} - seek location\r\n * @param callback {function} - callback function\r\n */\r\nfunction readLocation(location, callback) {\r\n  //console.log('## read location ', this.fileName, location);\r\n  var\r\n    file = this,\r\n    str = '',\r\n    len = file.nominalLineLength,\r\n    buffer = new Buffer.alloc(len);\r\n\r\n  readChunk(location, function(err, count) {\r\n    if (err) {\r\n      //console.log(err);\r\n      callback(err);\r\n      return;\r\n    }\r\n    //console.log('  read %d bytes at <%d>', count, location);\r\n    callback(null, lineDataToJSON(str, location));\r\n  });\r\n\r\n  function readChunk(pos, cb) {\r\n    var nonDataErr = new Error('no data at offset ' + pos);\r\n\r\n    fs.read(file.fd, buffer, 0, len, pos, function (err, count) {\r\n      if (!count) return cb(nonDataErr, count);\r\n\r\n      str += buffer.toString('ascii');\r\n      var eol = str.indexOf('\\n');\r\n      //console.log('  -- read %d bytes at <%d>', count, pos, eol);\r\n      if (count && eol === -1 && len < file.maxLineLength) {\r\n        // continue reading\r\n        return readChunk(pos + count, cb);\r\n      }\r\n\r\n      str = str.substr(0, eol);\r\n      if (str === '' && !err) err = nonDataErr;\r\n      cb(err, count);\r\n    });\r\n  }\r\n}\r\n\r\n/**\r\n * main lookup function\r\n *\r\n * @param offsets {array} - array of offsets to lookup (obtained from index.find())\r\n * @param callback{function} (optional) - callback function\r\n * @returns {Promise}\r\n */\r\nfunction lookup(offsets, callback) {\r\n  var results = [],\r\n    self = this,\r\n    single = !_.isArray(offsets);\r\n\r\n  if (single) offsets = [offsets];\r\n  return new Promise(function(resolve, reject) {\r\n    offsets\r\n      .map(function (offset) {\r\n        return _.partial(readLocation.bind(self), offset);\r\n      })\r\n      .map(promisifyInto(results))\r\n      .reduce(serialize, openFile())\r\n      .then(done)\r\n      .catch(done);\r\n\r\n    function done(lastResult) {\r\n      closeFile();\r\n      if (lastResult instanceof Error) {\r\n        callback && callback(lastResult, single ? {} :[]);\r\n        reject(lastResult);\r\n      } else {\r\n        if (single) results = results[0];\r\n        callback && callback(null, results);\r\n        resolve(results);\r\n      }\r\n    }\r\n  });\r\n\r\n  function serialize(prev, next) {\r\n    return prev.then(next);\r\n  }\r\n\r\n  function openFile() {\r\n    if (!self.fd) {\r\n      // console.log(' ... opening', self.filePath);\r\n      self.fd = fs.openSync(self.filePath, 'r');\r\n    }\r\n    // ref count so we know when to close the main index file\r\n    ++self.refcount;\r\n    return Promise.resolve();\r\n  }\r\n\r\n  function closeFile() {\r\n    if (--self.refcount === 0) {\r\n      // console.log(' ... closing', self.filePath);\r\n      fs.closeSync(self.fd);\r\n      self.fd = null;\r\n    }\r\n    return Promise.resolve();\r\n  }\r\n}\r\n\r\n/**\r\n * turn ordinary function into a promising one!\r\n *\r\n * @param collect {Array} - used to collect results\r\n * @returns {Function}\r\n */\r\nfunction promisifyInto(collect) {\r\n  return function(fn) {\r\n    return function() {\r\n      return new Promise(function (resolve, reject) {\r\n        fn(function (error, result) {   // Note: callback signature!\r\n          if (error) {\r\n            reject(error);\r\n          }\r\n          else {\r\n            collect && collect.push(result);\r\n            resolve(result);\r\n          }\r\n        });\r\n      });\r\n    };\r\n  }\r\n}\r\n\r\n\r\n/**\r\n * DataFile class\r\n *\r\n * @param dictPath {string} - path to dict folder\r\n * @param name {string} - POS name\r\n * @constructor\r\n */\r\nvar DataFile = function(dictPath, name) {\r\n  this.dictPath = dictPath;\r\n  this.fileName = 'data.' + name;\r\n  this.filePath = path.join(this.dictPath, this.fileName);\r\n\r\n  this.maxLineLength = DataFile.MAX_LINE_LENGTH[ name ];\r\n  this.nominalLineLength = MAX_SINGLE_READ_LENGTH;\r\n  this.refcount = 0;\r\n};\r\n\r\n/**\r\n * maximum read length at a time\r\n * @type {Number}\r\n */\r\nvar MAX_SINGLE_READ_LENGTH = 512;\r\n\r\n/**\r\n * lookup\r\n */\r\nDataFile.prototype.lookup = lookup;\r\n\r\n\r\n/**\r\n * maximum line length in each data file - used to optimize reads\r\n *\r\n * wc -L data.adv as of v3.1\r\n */\r\nDataFile.MAX_LINE_LENGTH = {\r\n  noun: 12972,\r\n  verb: 7713,\r\n  adj: 2794,\r\n  adv: 638\r\n};\r\n\r\n/**\r\n * map of lexFilenum to lex names\r\n *\r\n * @see https://wordnet.princeton.edu/wordnet/man/lexnames.5WN.html\r\n * @type {string[]}\r\n */\r\nDataFile.LEX_NAMES = [\r\n  'adj.all',\r\n  'adj.pert',\r\n  'adv.all',\r\n  'noun.Tops',\r\n  'noun.act',\r\n  'noun.animal',\r\n  'noun.artifact',\r\n  'noun.attribute',\r\n  'noun.body',\r\n  'noun.cognition',\r\n  'noun.communication',\r\n  'noun.event',\r\n  'noun.feeling',\r\n  'noun.food',\r\n  'noun.group',\r\n  'noun.location',\r\n  'noun.motive',\r\n  'noun.object',\r\n  'noun.person',\r\n  'noun.phenomenon',\r\n  'noun.plant',\r\n  'noun.possession',\r\n  'noun.process',\r\n  'noun.quantity',\r\n  'noun.relation',\r\n  'noun.shape',\r\n  'noun.state',\r\n  'noun.substance',\r\n  'noun.time',\r\n  'verb.body',\r\n  'verb.change',\r\n  'verb.cognition',\r\n  'verb.communication',\r\n  'verb.competition',\r\n  'verb.consumption',\r\n  'verb.contact',\r\n  'verb.creation',\r\n  'verb.emotion',\r\n  'verb.motion',\r\n  'verb.perception',\r\n  'verb.possession',\r\n  'verb.social',\r\n  'verb.stative',\r\n  'verb.weather',\r\n  'adj.ppl'\r\n];\r\n\r\nmodule.exports = DataFile;\r\n"]},"metadata":{},"sourceType":"script"}