{"ast":null,"code":"var _jsxFileName = \"/Users/tenzy/Documents/work/vata-hackathon-fe/atva/src/components/Utils/Speech2Text/index.js\";\nimport React, { Fragment } from \"react\";\n\nconst withS2T = BaseComponent => {\n  var _temp;\n\n  return _temp = class Speech2Text extends React.Component {\n    constructor(props) {\n      super(props);\n\n      this.init = () => {\n        this.recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();\n        this.recognition.continuous = false;\n        this.recognition.interimResults = false; //Define some more additional parameters for the recognition:\n\n        this.recognition.lang = \"en-GB\"; //Since from our experience, the highest result is really the best...\n\n        this.recognition.maxAlternatives = 1;\n\n        this.recognition.onspeechend = () => {\n          this.recognition.stop();\n        };\n\n        this.recognition.onend = () => {\n          this.setState({\n            isPlaying: false\n          });\n\n          if (!this.state.UIStop && !this.state.isPlaying) {\n            this.recognition.start();\n          }\n        };\n\n        this.recognition.onerror = error => {\n          console.error(error);\n        };\n\n        this.recognition.onstart = () => {\n          this.setState({\n            isPlaying: true\n          });\n        };\n\n        this.recognition.onresult = event => {\n          this.setState({\n            currentText: event.results[0][0].transcript + \". \"\n          });\n          /* Append the result */\n        };\n      };\n\n      this.startRecord = () => {\n        this.setState({\n          UIStop: false\n        });\n\n        if (!this.state.isPlaying) {\n          this.setState({\n            isPlaying: true\n          });\n          this.recognition.start();\n        }\n      };\n\n      this.stopRecord = () => {\n        this.setState({\n          UIStop: true\n        });\n        this.recognition.stop();\n      };\n\n      this.state = {\n        currentText: \"\",\n        UIStop: false,\n        isPlaying: false\n      };\n      this.init();\n    }\n\n    render() {\n      return React.createElement(Fragment, {\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 63\n        },\n        __self: this\n      }, React.createElement(BaseComponent, Object.assign({}, this.props, {\n        startRecord: this.startRecord,\n        stopRecord: this.stopRecord,\n        lastRecordedTranscript: this.state.currentText,\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 64\n        },\n        __self: this\n      })));\n    }\n\n  }, _temp;\n};\n\nexport default withS2T;","map":{"version":3,"sources":["/Users/tenzy/Documents/work/vata-hackathon-fe/atva/src/components/Utils/Speech2Text/index.js"],"names":["React","Fragment","withS2T","BaseComponent","Speech2Text","Component","constructor","props","init","recognition","window","SpeechRecognition","webkitSpeechRecognition","continuous","interimResults","lang","maxAlternatives","onspeechend","stop","onend","setState","isPlaying","state","UIStop","start","onerror","error","console","onstart","onresult","event","currentText","results","transcript","startRecord","stopRecord","render"],"mappings":";AAAA,OAAOA,KAAP,IAAgBC,QAAhB,QAAgC,OAAhC;;AAEA,MAAMC,OAAO,GAAIC,aAAD,IAAmB;AAAA;;AACjC,iBAAO,MAAMC,WAAN,SAA0BJ,KAAK,CAACK,SAAhC,CAA0C;AAE/CC,IAAAA,WAAW,CAACC,KAAD,EAAQ;AACjB,YAAMA,KAAN;;AADiB,WAUnBC,IAVmB,GAUZ,MAAM;AACX,aAAKC,WAAL,GAAmB,KAAKC,MAAM,CAACC,iBAAP,IAA4BD,MAAM,CAACE,uBAAxC,GAAnB;AACA,aAAKH,WAAL,CAAiBI,UAAjB,GAA8B,KAA9B;AACA,aAAKJ,WAAL,CAAiBK,cAAjB,GAAkC,KAAlC,CAHW,CAIX;;AACA,aAAKL,WAAL,CAAiBM,IAAjB,GAAwB,OAAxB,CALW,CAMX;;AACA,aAAKN,WAAL,CAAiBO,eAAjB,GAAmC,CAAnC;;AAEA,aAAKP,WAAL,CAAiBQ,WAAjB,GAA+B,MAAM;AACnC,eAAKR,WAAL,CAAiBS,IAAjB;AACD,SAFD;;AAGA,aAAKT,WAAL,CAAiBU,KAAjB,GAAyB,MAAM;AAC7B,eAAKC,QAAL,CAAc;AAACC,YAAAA,SAAS,EAAE;AAAZ,WAAd;;AACA,cAAI,CAAC,KAAKC,KAAL,CAAWC,MAAZ,IAAsB,CAAC,KAAKD,KAAL,CAAWD,SAAtC,EAAgD;AAC9C,iBAAKZ,WAAL,CAAiBe,KAAjB;AACD;AACF,SALD;;AAOA,aAAKf,WAAL,CAAiBgB,OAAjB,GAA4BC,KAAD,IAAW;AACpCC,UAAAA,OAAO,CAACD,KAAR,CAAcA,KAAd;AACD,SAFD;;AAIA,aAAKjB,WAAL,CAAiBmB,OAAjB,GAA2B,MAAM;AAC/B,eAAKR,QAAL,CAAc;AAACC,YAAAA,SAAS,EAAE;AAAZ,WAAd;AACD,SAFD;;AAIA,aAAKZ,WAAL,CAAiBoB,QAAjB,GAA6BC,KAAD,IAAW;AACrC,eAAKV,QAAL,CAAc;AAAEW,YAAAA,WAAW,EAAED,KAAK,CAACE,OAAN,CAAc,CAAd,EAAiB,CAAjB,EAAoBC,UAApB,GAAiC;AAAhD,WAAd;AAAsE;AACvE,SAFD;AAGD,OAxCkB;;AAAA,WA0CnBC,WA1CmB,GA0CL,MAAM;AAClB,aAAKd,QAAL,CAAc;AAACG,UAAAA,MAAM,EAAE;AAAT,SAAd;;AACA,YAAG,CAAC,KAAKD,KAAL,CAAWD,SAAf,EAA0B;AACxB,eAAKD,QAAL,CAAc;AAACC,YAAAA,SAAS,EAAE;AAAZ,WAAd;AACA,eAAKZ,WAAL,CAAiBe,KAAjB;AACD;AACF,OAhDkB;;AAAA,WAkDnBW,UAlDmB,GAkDN,MAAM;AACjB,aAAKf,QAAL,CAAc;AAACG,UAAAA,MAAM,EAAE;AAAT,SAAd;AACA,aAAKd,WAAL,CAAiBS,IAAjB;AACD,OArDkB;;AAEjB,WAAKI,KAAL,GAAa;AACXS,QAAAA,WAAW,EAAE,EADF;AAEXR,QAAAA,MAAM,EAAE,KAFG;AAGXF,QAAAA,SAAS,EAAE;AAHA,OAAb;AAKA,WAAKb,IAAL;AACD;;AA+CD4B,IAAAA,MAAM,GAAG;AACP,aACE,oBAAC,QAAD;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,SACE,oBAAC,aAAD,oBACM,KAAK7B,KADX;AAEE,QAAA,WAAW,EAAE,KAAK2B,WAFpB;AAGE,QAAA,UAAU,EAAE,KAAKC,UAHnB;AAIE,QAAA,sBAAsB,EAAE,KAAKb,KAAL,CAAWS,WAJrC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,SADF,CADF;AAUD;;AApE8C,GAAjD;AAsED,CAvED;;AAyEA,eAAe7B,OAAf","sourcesContent":["import React, { Fragment } from \"react\";\n\nconst withS2T = (BaseComponent) => {\n  return class Speech2Text extends React.Component {\n    recognition;\n    constructor(props) {\n      super(props);\n      this.state = {\n        currentText: \"\",\n        UIStop: false,\n        isPlaying: false,\n      };\n      this.init();\n    }\n\n    init = () => {\n      this.recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();\n      this.recognition.continuous = false;\n      this.recognition.interimResults = false;\n      //Define some more additional parameters for the recognition:\n      this.recognition.lang = \"en-GB\";\n      //Since from our experience, the highest result is really the best...\n      this.recognition.maxAlternatives = 1;\n\n      this.recognition.onspeechend = () => {\n        this.recognition.stop();\n      }\n      this.recognition.onend = () => {\n        this.setState({isPlaying: false});\n        if (!this.state.UIStop && !this.state.isPlaying){\n          this.recognition.start();\n        }\n      }\n\n      this.recognition.onerror = (error) => {\n        console.error(error);\n      }\n\n      this.recognition.onstart = () => {\n        this.setState({isPlaying: true});\n      }\n\n      this.recognition.onresult = (event) => {\n        this.setState({ currentText: event.results[0][0].transcript + \". \" }) /* Append the result */\n      }\n    }\n\n    startRecord = () => {\n      this.setState({UIStop: false})\n      if(!this.state.isPlaying) {\n        this.setState({isPlaying: true});\n        this.recognition.start();\n      }\n    }\n\n    stopRecord = () => {\n      this.setState({UIStop: true})\n      this.recognition.stop();\n    }\n\n    render() {\n      return (\n        <Fragment>\n          <BaseComponent\n            {...this.props}\n            startRecord={this.startRecord}\n            stopRecord={this.stopRecord}\n            lastRecordedTranscript={this.state.currentText}\n          />\n        </Fragment>\n      );\n    }\n  };\n};\n\nexport default withS2T;\n"]},"metadata":{},"sourceType":"module"}