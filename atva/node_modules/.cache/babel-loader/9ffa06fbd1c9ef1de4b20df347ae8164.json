{"ast":null,"code":"import _classCallCheck from\"/Users/tenzy/Documents/work/vata-hackathon-fe/atva/node_modules/@babel/runtime/helpers/esm/classCallCheck\";import _createClass from\"/Users/tenzy/Documents/work/vata-hackathon-fe/atva/node_modules/@babel/runtime/helpers/esm/createClass\";import _possibleConstructorReturn from\"/Users/tenzy/Documents/work/vata-hackathon-fe/atva/node_modules/@babel/runtime/helpers/esm/possibleConstructorReturn\";import _getPrototypeOf from\"/Users/tenzy/Documents/work/vata-hackathon-fe/atva/node_modules/@babel/runtime/helpers/esm/getPrototypeOf\";import _inherits from\"/Users/tenzy/Documents/work/vata-hackathon-fe/atva/node_modules/@babel/runtime/helpers/esm/inherits\";import React,{Fragment}from\"react\";var withS2T=function withS2T(BaseComponent){var _temp;return _temp=/*#__PURE__*/function(_React$Component){_inherits(Speech2Text,_React$Component);function Speech2Text(props){var _this;_classCallCheck(this,Speech2Text);_this=_possibleConstructorReturn(this,_getPrototypeOf(Speech2Text).call(this,props));_this.init=function(){_this.recognition=new(window.SpeechRecognition||window.webkitSpeechRecognition)();_this.recognition.continuous=false;_this.recognition.interimResults=false;//Define some more additional parameters for the recognition:\n_this.recognition.lang=\"en-GB\";//Since from our experience, the highest result is really the best...\n_this.recognition.maxAlternatives=1;_this.recognition.onspeechend=function(){_this.recognition.stop();};_this.recognition.onend=function(){_this.setState({isPlaying:false});if(!_this.state.UIStop&&!_this.state.isPlaying){_this.recognition.start();}};_this.recognition.onerror=function(error){console.error(error);};_this.recognition.onstart=function(){_this.setState({isPlaying:true});};_this.recognition.onresult=function(event){_this.setState({currentText:event.results[0][0].transcript+\". \"});/* Append the result */};};_this.startRecord=function(){_this.setState({UIStop:false});if(!_this.state.isPlaying){_this.setState({isPlaying:true});_this.recognition.start();}};_this.stopRecord=function(){_this.setState({UIStop:true});_this.recognition.stop();};_this.state={currentText:\"\",UIStop:false,isPlaying:false};_this.init();return _this;}_createClass(Speech2Text,[{key:\"render\",value:function render(){return React.createElement(Fragment,null,React.createElement(BaseComponent,Object.assign({},this.props,{startRecord:this.startRecord,stopRecord:this.stopRecord,lastRecordedTranscript:this.state.currentText})));}}]);return Speech2Text;}(React.Component),_temp;};export default withS2T;","map":{"version":3,"sources":["/Users/tenzy/Documents/work/vata-hackathon-fe/atva/src/components/Utils/Speech2Text/index.js"],"names":["React","Fragment","withS2T","BaseComponent","props","init","recognition","window","SpeechRecognition","webkitSpeechRecognition","continuous","interimResults","lang","maxAlternatives","onspeechend","stop","onend","setState","isPlaying","state","UIStop","start","onerror","error","console","onstart","onresult","event","currentText","results","transcript","startRecord","stopRecord","Component"],"mappings":"uqBAAA,MAAOA,CAAAA,KAAP,EAAgBC,QAAhB,KAAgC,OAAhC,CAEA,GAAMC,CAAAA,OAAO,CAAG,QAAVA,CAAAA,OAAU,CAACC,aAAD,CAAmB,WACjC,6FAEE,qBAAYC,KAAZ,CAAmB,6CACjB,6EAAMA,KAAN,GADiB,MAUnBC,IAVmB,CAUZ,UAAM,CACX,MAAKC,WAAL,CAAmB,IAAKC,MAAM,CAACC,iBAAP,EAA4BD,MAAM,CAACE,uBAAxC,GAAnB,CACA,MAAKH,WAAL,CAAiBI,UAAjB,CAA8B,KAA9B,CACA,MAAKJ,WAAL,CAAiBK,cAAjB,CAAkC,KAAlC,CACA;AACA,MAAKL,WAAL,CAAiBM,IAAjB,CAAwB,OAAxB,CACA;AACA,MAAKN,WAAL,CAAiBO,eAAjB,CAAmC,CAAnC,CAEA,MAAKP,WAAL,CAAiBQ,WAAjB,CAA+B,UAAM,CACnC,MAAKR,WAAL,CAAiBS,IAAjB,GACD,CAFD,CAGA,MAAKT,WAAL,CAAiBU,KAAjB,CAAyB,UAAM,CAC7B,MAAKC,QAAL,CAAc,CAACC,SAAS,CAAE,KAAZ,CAAd,EACA,GAAI,CAAC,MAAKC,KAAL,CAAWC,MAAZ,EAAsB,CAAC,MAAKD,KAAL,CAAWD,SAAtC,CAAgD,CAC9C,MAAKZ,WAAL,CAAiBe,KAAjB,GACD,CACF,CALD,CAOA,MAAKf,WAAL,CAAiBgB,OAAjB,CAA2B,SAACC,KAAD,CAAW,CACpCC,OAAO,CAACD,KAAR,CAAcA,KAAd,EACD,CAFD,CAIA,MAAKjB,WAAL,CAAiBmB,OAAjB,CAA2B,UAAM,CAC/B,MAAKR,QAAL,CAAc,CAACC,SAAS,CAAE,IAAZ,CAAd,EACD,CAFD,CAIA,MAAKZ,WAAL,CAAiBoB,QAAjB,CAA4B,SAACC,KAAD,CAAW,CACrC,MAAKV,QAAL,CAAc,CAAEW,WAAW,CAAED,KAAK,CAACE,OAAN,CAAc,CAAd,EAAiB,CAAjB,EAAoBC,UAApB,CAAiC,IAAhD,CAAd,EAAsE,uBACvE,CAFD,CAGD,CAxCkB,OA0CnBC,WA1CmB,CA0CL,UAAM,CAClB,MAAKd,QAAL,CAAc,CAACG,MAAM,CAAE,KAAT,CAAd,EACA,GAAG,CAAC,MAAKD,KAAL,CAAWD,SAAf,CAA0B,CACxB,MAAKD,QAAL,CAAc,CAACC,SAAS,CAAE,IAAZ,CAAd,EACA,MAAKZ,WAAL,CAAiBe,KAAjB,GACD,CACF,CAhDkB,OAkDnBW,UAlDmB,CAkDN,UAAM,CACjB,MAAKf,QAAL,CAAc,CAACG,MAAM,CAAE,IAAT,CAAd,EACA,MAAKd,WAAL,CAAiBS,IAAjB,GACD,CArDkB,CAEjB,MAAKI,KAAL,CAAa,CACXS,WAAW,CAAE,EADF,CAEXR,MAAM,CAAE,KAFG,CAGXF,SAAS,CAAE,KAHA,CAAb,CAKA,MAAKb,IAAL,GAPiB,aAQlB,CAVH,+DAyDW,CACP,MACE,qBAAC,QAAD,MACE,oBAAC,aAAD,kBACM,KAAKD,KADX,EAEE,WAAW,CAAE,KAAK2B,WAFpB,CAGE,UAAU,CAAE,KAAKC,UAHnB,CAIE,sBAAsB,CAAE,KAAKb,KAAL,CAAWS,WAJrC,GADF,CADF,CAUD,CApEH,yBAAiC5B,KAAK,CAACiC,SAAvC,QAsED,CAvED,CAyEA,cAAe/B,CAAAA,OAAf","sourcesContent":["import React, { Fragment } from \"react\";\n\nconst withS2T = (BaseComponent) => {\n  return class Speech2Text extends React.Component {\n    recognition;\n    constructor(props) {\n      super(props);\n      this.state = {\n        currentText: \"\",\n        UIStop: false,\n        isPlaying: false,\n      };\n      this.init();\n    }\n\n    init = () => {\n      this.recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();\n      this.recognition.continuous = false;\n      this.recognition.interimResults = false;\n      //Define some more additional parameters for the recognition:\n      this.recognition.lang = \"en-GB\";\n      //Since from our experience, the highest result is really the best...\n      this.recognition.maxAlternatives = 1;\n\n      this.recognition.onspeechend = () => {\n        this.recognition.stop();\n      }\n      this.recognition.onend = () => {\n        this.setState({isPlaying: false});\n        if (!this.state.UIStop && !this.state.isPlaying){\n          this.recognition.start();\n        }\n      }\n\n      this.recognition.onerror = (error) => {\n        console.error(error);\n      }\n\n      this.recognition.onstart = () => {\n        this.setState({isPlaying: true});\n      }\n\n      this.recognition.onresult = (event) => {\n        this.setState({ currentText: event.results[0][0].transcript + \". \" }) /* Append the result */\n      }\n    }\n\n    startRecord = () => {\n      this.setState({UIStop: false})\n      if(!this.state.isPlaying) {\n        this.setState({isPlaying: true});\n        this.recognition.start();\n      }\n    }\n\n    stopRecord = () => {\n      this.setState({UIStop: true})\n      this.recognition.stop();\n    }\n\n    render() {\n      return (\n        <Fragment>\n          <BaseComponent\n            {...this.props}\n            startRecord={this.startRecord}\n            stopRecord={this.stopRecord}\n            lastRecordedTranscript={this.state.currentText}\n          />\n        </Fragment>\n      );\n    }\n  };\n};\n\nexport default withS2T;\n"]},"metadata":{},"sourceType":"module"}