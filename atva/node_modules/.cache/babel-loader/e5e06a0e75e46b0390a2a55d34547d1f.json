{"ast":null,"code":"var _regeneratorRuntime = require(\"/Users/tenzy/Documents/work/vata-hackathon-fe/atva/node_modules/@babel/runtime/regenerator\");\n\nvar _classCallCheck = require(\"/Users/tenzy/Documents/work/vata-hackathon-fe/atva/node_modules/@babel/runtime/helpers/classCallCheck\");\n\nvar _createClass = require(\"/Users/tenzy/Documents/work/vata-hackathon-fe/atva/node_modules/@babel/runtime/helpers/createClass\");\n\nvar Preprocesser = require('./Preprocesser').Preprocesser;\n\nvar Summarizer =\n/*#__PURE__*/\nfunction () {\n  \"use strict\";\n\n  function Summarizer(string_to_process, number_of_sentences) {\n    _classCallCheck(this, Summarizer);\n\n    this.preprocesser = new Preprocesser();\n    this.number_of_sentences = number_of_sentences;\n    this.string_to_process = string_to_process;\n    this.new_length = 0;\n  } //Takes in a list of sentences and weights and sorts by weight.\n\n\n  _createClass(Summarizer, [{\n    key: \"sortSentences\",\n    value: function sortSentences(sentence_weights_list) {\n      sentence_weights_list.sort(function (a, b) {\n        return b[0] - a[0];\n      });\n      return sentence_weights_list;\n    } //Converts the textRank map into a list\n\n  }, {\n    key: \"textRankMapToList\",\n    value: function textRankMapToList(text_rank_map) {\n      var result_list = [];\n      text_rank_map.forEach(function (value, key, map) {\n        result_list.push([value, key]);\n      });\n      return result_list;\n    } //Takes in a list of sorted sentences and a map of those sentences to the original sentences. \n\n  }, {\n    key: \"listToString\",\n    value: function listToString(sorted_sentences, clean_sentences) {\n      var self = this;\n      var result_string = \"\";\n      var length_count = 0;\n      var count = self.number_of_sentences;\n\n      if (sorted_sentences.length < self.number_of_sentences) {\n        count = sorted_sentences.length;\n      }\n\n      for (var i = 0; i < count; i++) {\n        length_count += sorted_sentences[i][1].split(\" \").length;\n        result_string += clean_sentences[1].get(sorted_sentences[i][1]);\n      }\n\n      this.new_length = length_count;\n      return result_string;\n    }\n  }, {\n    key: \"summarizeByFrequency\",\n    value: function summarizeByFrequency() {\n      var self = this;\n      var list_to_clean = self.preprocesser.paragraphToSentences(self.string_to_process);\n      var clean_sentences = self.preprocesser.cleanSentences(list_to_clean);\n      var tokenized = self.preprocesser.tokenizeSentences(clean_sentences[0]);\n      var weighted_map = self.preprocesser.getWeights(tokenized);\n      var sentence_weights_list = self.preprocesser.sentenceWeights(clean_sentences[0], weighted_map);\n      var sorted_sentences = self.sortSentences(sentence_weights_list);\n      return {\n        summary: self.listToString(sorted_sentences, clean_sentences),\n        sentence_list: list_to_clean,\n        weighted_map: weighted_map,\n        sorted_sentences: sorted_sentences\n      };\n    }\n  }, {\n    key: \"summarizeByRank\",\n    value: function summarizeByRank() {\n      var self, list_to_clean, clean_sentences, nouns_and_adjactive_map, text_rank_graph, text_rank_map, text_rank_list;\n      return _regeneratorRuntime.async(function summarizeByRank$(_context) {\n        while (1) {\n          switch (_context.prev = _context.next) {\n            case 0:\n              self = this;\n              list_to_clean = self.preprocesser.paragraphToSentences(self.string_to_process);\n              clean_sentences = self.preprocesser.cleanSentences(list_to_clean);\n              _context.prev = 3;\n              _context.next = 6;\n              return _regeneratorRuntime.awrap(self.preprocesser.nounsAndAdjectives(clean_sentences[0]));\n\n            case 6:\n              nouns_and_adjactive_map = _context.sent;\n              text_rank_graph = self.preprocesser.createTextRankGraph(nouns_and_adjactive_map);\n              text_rank_map = self.preprocesser.textRank(text_rank_graph);\n              text_rank_list = self.sortSentences(self.textRankMapToList(text_rank_map)); //let list_to_pass_in = text_rank_list;\n\n              return _context.abrupt(\"return\", {\n                summary: self.listToString(text_rank_list, clean_sentences),\n                sentence_list: list_to_clean,\n                nouns_and_adjactive_map: nouns_and_adjactive_map\n              });\n\n            case 13:\n              _context.prev = 13;\n              _context.t0 = _context[\"catch\"](3);\n              console.log(_context.t0);\n\n            case 16:\n            case \"end\":\n              return _context.stop();\n          }\n        }\n      }, null, this, [[3, 13]]);\n    }\n  }]);\n\n  return Summarizer;\n}();\n\nmodule.exports.Summarizer = Summarizer;","map":{"version":3,"sources":["/Users/tenzy/Documents/work/vata-hackathon-fe/atva/node_modules/node-summarizer/src/Summarizer.js"],"names":["Preprocesser","require","Summarizer","string_to_process","number_of_sentences","preprocesser","new_length","sentence_weights_list","sort","a","b","text_rank_map","result_list","forEach","value","key","map","push","sorted_sentences","clean_sentences","self","result_string","length_count","count","length","i","split","get","list_to_clean","paragraphToSentences","cleanSentences","tokenized","tokenizeSentences","weighted_map","getWeights","sentenceWeights","sortSentences","summary","listToString","sentence_list","nounsAndAdjectives","nouns_and_adjactive_map","text_rank_graph","createTextRankGraph","textRank","text_rank_list","textRankMapToList","console","log","module","exports"],"mappings":";;;;;;AAAA,IAAMA,YAAY,GAAGC,OAAO,CAAC,gBAAD,CAAP,CAA0BD,YAA/C;;IAEME,U;;;;;AACL,sBAAYC,iBAAZ,EAA+BC,mBAA/B,EAAmD;AAAA;;AAClD,SAAKC,YAAL,GAAoB,IAAIL,YAAJ,EAApB;AACA,SAAKI,mBAAL,GAA2BA,mBAA3B;AACA,SAAKD,iBAAL,GAAyBA,iBAAzB;AACA,SAAKG,UAAL,GAAkB,CAAlB;AACA,G,CAED;;;;;kCACcC,qB,EAAsB;AACnCA,MAAAA,qBAAqB,CAACC,IAAtB,CAA2B,UAACC,CAAD,EAAGC,CAAH,EAAO;AACjC,eAAOA,CAAC,CAAC,CAAD,CAAD,GAAKD,CAAC,CAAC,CAAD,CAAb;AACA,OAFD;AAGA,aAAOF,qBAAP;AACA,K,CAED;;;;sCACkBI,a,EAAc;AAC/B,UAAIC,WAAW,GAAG,EAAlB;AACAD,MAAAA,aAAa,CAACE,OAAd,CAAsB,UAACC,KAAD,EAAQC,GAAR,EAAaC,GAAb,EAAmB;AACxCJ,QAAAA,WAAW,CAACK,IAAZ,CAAiB,CAACH,KAAD,EAAOC,GAAP,CAAjB;AACA,OAFD;AAIA,aAAOH,WAAP;AACA,K,CAED;;;;iCACaM,gB,EAAkBC,e,EAAgB;AAC9C,UAAMC,IAAI,GAAG,IAAb;AACA,UAAIC,aAAa,GAAG,EAApB;AACA,UAAIC,YAAY,GAAG,CAAnB;AACA,UAAIC,KAAK,GAAGH,IAAI,CAAChB,mBAAjB;;AACA,UAAGc,gBAAgB,CAACM,MAAjB,GAA0BJ,IAAI,CAAChB,mBAAlC,EAAsD;AACrDmB,QAAAA,KAAK,GAAGL,gBAAgB,CAACM,MAAzB;AACA;;AACD,WAAI,IAAIC,CAAC,GAAC,CAAV,EAAaA,CAAC,GAACF,KAAf,EAAsBE,CAAC,EAAvB,EAA0B;AACzBH,QAAAA,YAAY,IAAIJ,gBAAgB,CAACO,CAAD,CAAhB,CAAoB,CAApB,EAAuBC,KAAvB,CAA6B,GAA7B,EAAkCF,MAAlD;AACAH,QAAAA,aAAa,IAAEF,eAAe,CAAC,CAAD,CAAf,CAAmBQ,GAAnB,CAAuBT,gBAAgB,CAACO,CAAD,CAAhB,CAAoB,CAApB,CAAvB,CAAf;AACA;;AACD,WAAKnB,UAAL,GAAkBgB,YAAlB;AACA,aAAOD,aAAP;AACA;;;2CAEqB;AACrB,UAAMD,IAAI,GAAG,IAAb;AACA,UAAMQ,aAAa,GAAGR,IAAI,CAACf,YAAL,CAAkBwB,oBAAlB,CAAuCT,IAAI,CAACjB,iBAA5C,CAAtB;AACA,UAAMgB,eAAe,GAAGC,IAAI,CAACf,YAAL,CAAkByB,cAAlB,CAAiCF,aAAjC,CAAxB;AACA,UAAMG,SAAS,GAAGX,IAAI,CAACf,YAAL,CAAkB2B,iBAAlB,CAAoCb,eAAe,CAAC,CAAD,CAAnD,CAAlB;AACA,UAAMc,YAAY,GAAGb,IAAI,CAACf,YAAL,CAAkB6B,UAAlB,CAA6BH,SAA7B,CAArB;AACA,UAAMxB,qBAAqB,GAAGa,IAAI,CAACf,YAAL,CAAkB8B,eAAlB,CAAkChB,eAAe,CAAC,CAAD,CAAjD,EAAsDc,YAAtD,CAA9B;AACA,UAAMf,gBAAgB,GAAGE,IAAI,CAACgB,aAAL,CAAmB7B,qBAAnB,CAAzB;AAEA,aAAO;AACN8B,QAAAA,OAAO,EAAEjB,IAAI,CAACkB,YAAL,CAAkBpB,gBAAlB,EAAoCC,eAApC,CADH;AAENoB,QAAAA,aAAa,EAAEX,aAFT;AAGNK,QAAAA,YAAY,EAAEA,YAHR;AAINf,QAAAA,gBAAgB,EAAEA;AAJZ,OAAP;AAMA;;;;;;;;;AAGME,cAAAA,I,GAAO,I;AACPQ,cAAAA,a,GAAgBR,IAAI,CAACf,YAAL,CAAkBwB,oBAAlB,CAAuCT,IAAI,CAACjB,iBAA5C,C;AAChBgB,cAAAA,e,GAAkBC,IAAI,CAACf,YAAL,CAAkByB,cAAlB,CAAiCF,aAAjC,C;;;+CAEeR,IAAI,CAACf,YAAL,CAAkBmC,kBAAlB,CAAqCrB,eAAe,CAAC,CAAD,CAApD,C;;;AAAhCsB,cAAAA,uB;AACFC,cAAAA,e,GAAkBtB,IAAI,CAACf,YAAL,CAAkBsC,mBAAlB,CAAsCF,uBAAtC,C;AAClB9B,cAAAA,a,GAAgBS,IAAI,CAACf,YAAL,CAAkBuC,QAAlB,CAA2BF,eAA3B,C;AAChBG,cAAAA,c,GAAiBzB,IAAI,CAACgB,aAAL,CAAmBhB,IAAI,CAAC0B,iBAAL,CAAuBnC,aAAvB,CAAnB,C,EACrB;;+CACO;AACN0B,gBAAAA,OAAO,EAAEjB,IAAI,CAACkB,YAAL,CAAkBO,cAAlB,EAAkC1B,eAAlC,CADH;AAENoB,gBAAAA,aAAa,EAAEX,aAFT;AAGNa,gBAAAA,uBAAuB,EAAEA;AAHnB,e;;;;;AAMPM,cAAAA,OAAO,CAACC,GAAR;;;;;;;;;;;;;;AAKHC,MAAM,CAACC,OAAP,CAAehD,UAAf,GAA4BA,UAA5B","sourcesContent":["const Preprocesser = require('./Preprocesser').Preprocesser;\n\nclass Summarizer{\n\tconstructor(string_to_process, number_of_sentences){\n\t\tthis.preprocesser = new Preprocesser();\n\t\tthis.number_of_sentences = number_of_sentences;\n\t\tthis.string_to_process = string_to_process;\n\t\tthis.new_length = 0;\n\t}\n\n\t//Takes in a list of sentences and weights and sorts by weight.\n\tsortSentences(sentence_weights_list){\n\t\tsentence_weights_list.sort((a,b)=>{\n\t\t\treturn b[0]-a[0];\n\t\t})\n\t\treturn sentence_weights_list;\n\t}\n\n\t//Converts the textRank map into a list\n\ttextRankMapToList(text_rank_map){\n\t\tlet result_list = [];\n\t\ttext_rank_map.forEach((value, key, map)=>{\n\t\t\tresult_list.push([value,key]);\n\t\t})\n\n\t\treturn result_list;\n\t}\n\n\t//Takes in a list of sorted sentences and a map of those sentences to the original sentences. \n\tlistToString(sorted_sentences, clean_sentences){\n\t\tconst self = this;\n\t\tlet result_string = \"\";\n\t\tlet length_count = 0;\n\t\tlet count = self.number_of_sentences;\n\t\tif(sorted_sentences.length < self.number_of_sentences){\n\t\t\tcount = sorted_sentences.length;\n\t\t}\n\t\tfor(var i=0; i<count; i++){\n\t\t\tlength_count += sorted_sentences[i][1].split(\" \").length;\n\t\t\tresult_string+=clean_sentences[1].get(sorted_sentences[i][1]);\n\t\t}\n\t\tthis.new_length = length_count;\n\t\treturn result_string;\n\t}\n\n\tsummarizeByFrequency(){\n\t\tconst self = this\n\t\tconst list_to_clean = self.preprocesser.paragraphToSentences(self.string_to_process);\n\t\tconst clean_sentences = self.preprocesser.cleanSentences(list_to_clean);\n\t\tconst tokenized = self.preprocesser.tokenizeSentences(clean_sentences[0]);\n\t\tconst weighted_map = self.preprocesser.getWeights(tokenized);\n\t\tconst sentence_weights_list = self.preprocesser.sentenceWeights(clean_sentences[0], weighted_map);\n\t\tconst sorted_sentences = self.sortSentences(sentence_weights_list);\n\t\t\n\t\treturn {\n\t\t\tsummary: self.listToString(sorted_sentences, clean_sentences),\n\t\t\tsentence_list: list_to_clean,\n\t\t\tweighted_map: weighted_map,\n\t\t\tsorted_sentences: sorted_sentences\n\t\t}\n\t}\n\n\tasync summarizeByRank(){\n\t\tconst self = this;\n\t\tconst list_to_clean = self.preprocesser.paragraphToSentences(self.string_to_process);\n\t\tconst clean_sentences = self.preprocesser.cleanSentences(list_to_clean);\n\t\ttry{\n\t\t\tconst nouns_and_adjactive_map = await self.preprocesser.nounsAndAdjectives(clean_sentences[0]);\n\t\t\tlet text_rank_graph = self.preprocesser.createTextRankGraph(nouns_and_adjactive_map);\n\t\t\tlet text_rank_map = self.preprocesser.textRank(text_rank_graph);\n\t\t\tlet text_rank_list = self.sortSentences(self.textRankMapToList(text_rank_map));\n\t\t\t//let list_to_pass_in = text_rank_list;\n\t\t\treturn {\n\t\t\t\tsummary: self.listToString(text_rank_list, clean_sentences),\n\t\t\t\tsentence_list: list_to_clean,\n\t\t\t\tnouns_and_adjactive_map: nouns_and_adjactive_map\n\t\t\t}\n\t\t}catch(err){\n\t\t\tconsole.log(err);\n\t\t}\n\t}\n}\n\nmodule.exports.Summarizer = Summarizer;"]},"metadata":{},"sourceType":"script"}